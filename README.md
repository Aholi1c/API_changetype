# Get_data é¡¹ç›®æ–‡æ¡£

## é¡¹ç›®æ¦‚è¿°

Get_data æ˜¯ä¸€ä¸ªç”¨äºæ”¶é›†ã€å¤„ç†å’Œåˆ†æç¼–ç¨‹è¯­è¨€åŒ…APIå˜æ›´ä¿¡æ¯çš„è‡ªåŠ¨åŒ–æµç¨‹ã€‚è¯¥é¡¹ç›®é€šè¿‡çˆ¬è™«æŠ€æœ¯æ”¶é›†APIå˜æ›´çš„URLï¼Œç»è¿‡å¤šè½®å¤„ç†å’Œæ™ºèƒ½åˆ†æï¼Œæœ€ç»ˆç”Ÿæˆç»“æ„åŒ–çš„APIå˜æ›´æ•°æ®å’Œä»£ç ç¤ºä¾‹ã€‚
æœ¬é¡¹ç›®æä¾›éƒ¨åˆ†ç”¨äºæµ‹è¯•çš„æ•°æ®é›†


## ğŸ—ï¸ é¡¹ç›®ç»“æ„

```
Get_data/
â”œâ”€â”€ WebAgent/                     # WebAgentæ¡†æ¶ï¼ˆæ ¸å¿ƒçˆ¬è™«å·¥å…·ï¼‰
â”‚   â”œâ”€â”€ api_crawler.py           # ç¬¬ä¸€é˜¶æ®µï¼šåŸºç¡€çˆ¬è™«
â”‚   â”œâ”€â”€ api_crawler_gpt.py       # ç¬¬äºŒé˜¶æ®µï¼šGPTå¢å¼ºçˆ¬è™«
â”‚   â”œâ”€â”€ visit_gpt4o_fixed.py     # GPT-4oé¡µé¢è®¿é—®å·¥å…·
â”‚   â”œâ”€â”€ pre_process/             # é¢„å¤„ç†æ¨¡å—
â”‚   â”‚   â”œâ”€â”€ preprocess_data.py   # æ•°æ®è¿‡æ»¤è„šæœ¬
â”‚   â”‚   â””â”€â”€ preprocess_data/     # å¢å¼ºå¤„ç†å·¥å…·
â”‚   â”‚       â”œâ”€â”€ enhanced_api_crawler.py  # æ™ºèƒ½APIè¯†åˆ«çˆ¬è™«
â”‚   â”‚       â”œâ”€â”€ enhanced_lodash_processor.py  # Lodashç¤ºä¾‹æå–å™¨
â”‚   â”‚       â””â”€â”€ enhanced_processor.py        # é€šç”¨ç¤ºä¾‹æå–å™¨
â”‚   â”œâ”€â”€ api_crawl_results_*.csv  # ç¬¬ä¸€é˜¶æ®µçˆ¬å–ç»“æœï¼ˆåŸå§‹æ•°æ®ï¼‰
â”‚   â”œâ”€â”€ api_crawl_temp_*.csv     # ä¸´æ—¶çˆ¬å–æ–‡ä»¶
â”‚   â””â”€â”€ preprocess_*.csv         # é¢„å¤„ç†åçš„æ•°æ®
â””â”€â”€ WebAgent/                    # WebAgentæ ¸å¿ƒæ¡†æ¶
    â””â”€â”€ WebAgent/                # WebAgentæºä»£ç 
```

## ğŸ”„ å·¥ä½œæµç¨‹

### ç¬¬ä¸€é˜¶æ®µï¼šæ•°æ®æ”¶é›†

#### 1.1 å‡†å¤‡URLè¾“å…¥æ–‡ä»¶
åˆ›å»º `input.csv` æ–‡ä»¶ï¼ŒåŒ…å«éœ€è¦çˆ¬å–çš„URLï¼š
```csv
url
https://example.com/api/doc1
https://example.com/api/doc2
```

#### 1.2 è¿è¡ŒåŸºç¡€çˆ¬è™« (`api_crawler.py`)

**åŠŸèƒ½**ï¼š
- æ‰¹é‡çˆ¬å–URLåˆ—è¡¨
- æå–åŸºç¡€çš„APIä¿¡æ¯
- æ”¯æŒæ–­ç‚¹ç»­çˆ¬
- å¤šçº¿ç¨‹å¹¶å‘å¤„ç†

**ä½¿ç”¨æ–¹æ³•**ï¼š
```bash
cd Get_data/WebAgent
python api_crawler.py
```

**è¾“å‡º**ï¼š
- `api_crawl_results_[package].csv` - çˆ¬å–ç»“æœ
- `api_crawl_temp.csv` - ä¸´æ—¶æ–‡ä»¶ï¼ˆæ”¯æŒæ–­ç‚¹ç»­çˆ¬ï¼‰

**å­—æ®µè¯´æ˜**ï¼š
- `original_row_num` - åŸå§‹è¡Œå·
- `url` - æºURL
- `api` - APIåç§°
- `package` - åŒ…/åº“åç§°
- `language` - ç¼–ç¨‹è¯­è¨€
- `deprecated_in` - å¼ƒç”¨ç‰ˆæœ¬
- `removed_in` - ç§»é™¤ç‰ˆæœ¬
- `replaced_by` - æ›¿ä»£æ–¹æ¡ˆ
- `change_type` - å˜æ›´ç±»å‹
- `reason` - å˜æ›´åŸå› 
- `source` - æ¥æºé“¾æ¥

#### 1.3 è¿è¡ŒGPTå¢å¼ºçˆ¬è™« (`api_crawler_gpt.py`)

**åŠŸèƒ½**ï¼š
- ä½¿ç”¨GPTæ¨¡å‹å¯¹ç¬¬ä¸€é˜¶æ®µç»“æœè¿›è¡Œæ·±åº¦åˆ†æ
- æå–æ›´å‡†ç¡®çš„APIå˜æ›´ä¿¡æ¯
- è¡¥å……ç¼ºå¤±çš„å­—æ®µä¿¡æ¯

**ä½¿ç”¨æ–¹æ³•**ï¼š
```bash
cd Get_data/WebAgent
python api_crawler_gpt.py
```

**é…ç½®**ï¼š
- éœ€è¦é…ç½®OpenAI APIå¯†é’¥
- æ”¯æŒè‡ªå®šä¹‰GPTæ¨¡å‹é€‰æ‹©

### ç¬¬äºŒé˜¶æ®µï¼šæ•°æ®é¢„å¤„ç†

#### 2.1 æ•°æ®è¿‡æ»¤ (`preprocess_data.py`)

**åŠŸèƒ½**ï¼š
- è¿‡æ»¤æ²¡æœ‰å®é™…å˜æ›´çš„APIè®°å½•
- å¦‚æœ `deprecated_in`ã€`removed_in` å’Œ `replaced_by` ä¸‰åˆ—åŒæ—¶ä¸ºç©ºï¼Œåˆ™åˆ é™¤è¯¥è¡Œ

**ä½¿ç”¨æ–¹æ³•**ï¼š
```bash
cd Get_data/WebAgent/pre_process
# ä¿®æ”¹ preprocess_data.py ä¸­çš„æ–‡ä»¶å
python preprocess_data.py
```

**é…ç½®**ï¼š
éœ€è¦ä¿®æ”¹è„šæœ¬ä¸­çš„è¾“å…¥è¾“å‡ºæ–‡ä»¶åï¼š
```python
input_file = 'api_crawl_results_[package].csv'
output_file = 'preprocess_[package].csv'
```

### ç¬¬ä¸‰é˜¶æ®µï¼šå¢å¼ºå¤„ç†

#### 3.1 æ™ºèƒ½APIè¯†åˆ« (`enhanced_api_crawler.py`)

**åŠŸèƒ½**ï¼š
- ä½¿ç”¨GPT-4oæ™ºèƒ½è¯†åˆ«URLå¯¹åº”çš„API
- è§£å†³URLä¸APIä¸åŒ¹é…çš„é—®é¢˜
- æå–æ›´å‡†ç¡®çš„APIå˜æ›´ä¿¡æ¯

**ç‰¹æ€§**ï¼š
- å¤šå±‚APIè¯†åˆ«ç­–ç•¥ï¼ˆURL Fragmentã€è·¯å¾„ã€æŸ¥è¯¢å‚æ•°ï¼‰
- GPT-4oæ™ºèƒ½åˆ†æä¸å›é€€æœºåˆ¶
- æ”¯æŒReactã€Lodashç­‰æ¡†æ¶çš„ç‰¹æ®Šå¤„ç†

**ä½¿ç”¨æ–¹æ³•**ï¼š
```bash
cd Get_data/WebAgent/pre_process/preprocess_data
# ä¿®æ”¹é…ç½®
INPUT_CSV = "preprocess_[package].csv"
OUTPUT_CSV = "enhanced_api_crawl_results.csv"
python enhanced_api_crawler.py
```

**é…ç½®**ï¼š
```python
# Azure OpenAIé…ç½®
AZURE_ENDPOINT = "https://your-endpoint.openai.azure.com/"
AZURE_DEPLOYMENT = "gpt-4o"
AZURE_API_KEY = "your-api-key"
```

#### 3.2 ä»£ç ç¤ºä¾‹æå–

å¯¹äºéœ€è¦æå–ä»£ç ç¤ºä¾‹çš„APIï¼ˆå¦‚Reactå’ŒLodashï¼‰ï¼Œè¿è¡Œç›¸åº”çš„å¤„ç†å™¨ï¼š

##### Lodashç¤ºä¾‹æå– (`enhanced_lodash_processor.py`)

**åŠŸèƒ½**ï¼š
- ä»Lodashæ–‡æ¡£é¡µé¢æå–ä¸ç‰¹å®šAPIç›¸å…³çš„ä»£ç ç¤ºä¾‹
- æ™ºèƒ½è¯†åˆ«å’Œåˆ†ç¦»ä»£ç å—
- ç”ŸæˆåŒ…å«ä»£ç å’Œè¾“å‡ºçš„ç»“æ„åŒ–ç¤ºä¾‹

**ä½¿ç”¨æ–¹æ³•**ï¼š
```bash
cd Get_data/WebAgent/pre_process/preprocess_data
# ä¿®æ”¹é…ç½®
csv_file = 'preprocess_Lodash.csv'
output_file = 'enhanced_lodash_examples.json'
python enhanced_lodash_processor.py
```

##### é€šç”¨ç¤ºä¾‹æå– (`enhanced_processor.py`)

**åŠŸèƒ½**ï¼š
- é€šç”¨æ¡†æ¶çš„ä»£ç ç¤ºä¾‹æå–
- æ”¯æŒå¤šç§æ–‡æ¡£æ ¼å¼
- GPTæ™ºèƒ½åŒ¹é…APIä¸ç¤ºä¾‹

## ğŸ“Š æ•°æ®æµç¨‹å›¾

```
URLåˆ—è¡¨ â†’ api_crawler.py â†’ api_crawler_results.csv
                    â†“
           api_crawler_gpt.py â†’ å¢å¼ºçš„çˆ¬å–ç»“æœ
                    â†“
            preprocess_data.py â†’ preprocess_[package].csv
                    â†“
        enhanced_api_crawler.py â†’ å®Œå–„çš„APIåˆ†æç»“æœ
                    â†“
        enhanced_processor.py â†’ APIä»£ç ç¤ºä¾‹ï¼ˆå¯é€‰ï¼‰
```

## ğŸ”§ é…ç½®è¯´æ˜

### ç¯å¢ƒè¦æ±‚

- Python 3.7+
- pandas
- requests
- beautifulsoup4
- openai
- azure-openai

### APIå¯†é’¥é…ç½®

1. **OpenAI API**ï¼ˆç”¨äº api_crawler_gpt.pyï¼‰ï¼š
```python
OPENAI_API_KEY = "your-openai-api-key"
```

2. **Azure OpenAI API**ï¼ˆç”¨äº enhanced_* è„šæœ¬ï¼‰ï¼š
```python
AZURE_ENDPOINT = "https://your-endpoint.openai.azure.com/"
AZURE_DEPLOYMENT = "gpt-4o"
AZURE_API_KEY = "your-azure-api-key"
```

## ğŸ“‹ æ”¯æŒçš„ç¼–ç¨‹è¯­è¨€å’ŒåŒ…

### Pythonç”Ÿæ€
- **NumPy** - æ•°å€¼è®¡ç®—åº“
- **Pandas** - æ•°æ®åˆ†æåº“
- **Django** - Webæ¡†æ¶
- **Flask** - Webå¾®æ¡†æ¶
- **PyTorch** - æ·±åº¦å­¦ä¹ æ¡†æ¶
- **TensorFlow** - æœºå™¨å­¦ä¹ æ¡†æ¶
- **scikit-learn** - æœºå™¨å­¦ä¹ åº“
- **OpenCV** - è®¡ç®—æœºè§†è§‰åº“
- **SQLAlchemy** - SQLå·¥å…·åŒ…
- **Requests** - HTTPåº“

### Javaç”Ÿæ€
- **Spring Framework** - åº”ç”¨æ¡†æ¶
- **Hibernate** - ORMæ¡†æ¶
- **Java SE** - æ ‡å‡†ç‰ˆAPI

### JavaScriptç”Ÿæ€
- **React** - UIåº“
- **Lodash** - å®ç”¨å·¥å…·åº“
- **Angular** - åº”ç”¨æ¡†æ¶
- **Vue.js** - æ¸è¿›å¼æ¡†æ¶
- **TypeScript** - ç±»å‹ç³»ç»Ÿ

### å…¶ä»–è¯­è¨€
- **Go** - ç¼–ç¨‹è¯­è¨€æ ‡å‡†åº“
- **Ruby** - ç¼–ç¨‹è¯­è¨€æ ¸å¿ƒåº“
- **Scala** - å‡½æ•°å¼ç¼–ç¨‹è¯­è¨€
- **C++** - æ ‡å‡†åº“
- **Boost** - C++åº“é›†åˆ

## ğŸ“ˆ è¾“å‡ºæ•°æ®æ ¼å¼

### æœ€ç»ˆJSONç¤ºä¾‹

```json
{
  "source_url": "https://numpy.org/doc/.../ndarray.shape.html",
  "api": "numpy.ndarray.shape",
  "package": "NumPy",
  "change_type": "API Usage Discouraged",
  "reason": "Setting `arr.shape` is discouraged...",
  "has_examples": true,
  "examples": [
    {
      "code": "import numpy as np\nx = np.array([1, 2, 3])\nx.shape",
      "output": "(3,)"
    }
  ],
  "examples_count": 1,
  "extraction_method": "GPT-4o Enhanced"
}
```

## âš¡ æ€§èƒ½ä¼˜åŒ–å»ºè®®

1. **å¹¶å‘è®¾ç½®**ï¼š
   - è°ƒæ•´ `MAX_WORKERS` ä»¥é€‚åº”ä½ çš„ç½‘ç»œå’ŒCPUèƒ½åŠ›
   - æ¨è 8-16 ä¸ªçº¿ç¨‹

2. **æ‰¹é‡å¤„ç†**ï¼š
   - ä½¿ç”¨ `BATCH_SIZE` æ§åˆ¶å†…å­˜ä½¿ç”¨
   - æ¨è 50-100 çš„æ‰¹é‡å¤§å°

3. **æ–­ç‚¹ç»­çˆ¬**ï¼š
   - åˆ©ç”¨ä¸´æ—¶æ–‡ä»¶æ”¯æŒä¸­æ–­æ¢å¤
   - é¿å…é‡å¤çˆ¬å–å·²å®Œæˆçš„URL

## ğŸ› å¸¸è§é—®é¢˜

### 1. çˆ¬è™«è¢«é™åˆ¶è®¿é—®
**è§£å†³æ–¹æ¡ˆ**ï¼š
- é™ä½å¹¶å‘æ•°
- å¢åŠ é‡è¯•é—´éš”
- ä½¿ç”¨ä»£ç†

### 2. GPT APIè°ƒç”¨å¤±è´¥
**è§£å†³æ–¹æ¡ˆ**ï¼š
- æ£€æŸ¥APIå¯†é’¥é…ç½®
- ç¡®è®¤è´¦æˆ·ä½™é¢
- ä½¿ç”¨å›é€€æœºåˆ¶

### 3. CSVæ–‡ä»¶ç¼–ç é—®é¢˜
**è§£å†³æ–¹æ¡ˆ**ï¼š
- ç¡®ä¿ä½¿ç”¨ UTF-8 ç¼–ç 
- æ£€æŸ¥ç‰¹æ®Šå­—ç¬¦å¤„ç†

## ğŸ“ ä½¿ç”¨ç¤ºä¾‹

### å®Œæ•´æµç¨‹ç¤ºä¾‹ï¼ˆä»¥NumPyä¸ºä¾‹ï¼‰

```bash
# 1. å‡†å¤‡URLåˆ—è¡¨
echo "url" > input.csv
echo "https://numpy.org/doc/stable/reference/generated/numpy.ndarray.shape.html" >> input.csv

# 2. è¿è¡ŒåŸºç¡€çˆ¬è™«
cd Get_data/WebAgent
python api_crawler.py

# 3. è¿è¡ŒGPTå¢å¼º
python api_crawler_gpt.py

# 4. æ•°æ®é¢„å¤„ç†
cd pre_process
# ä¿®æ”¹ preprocess_data.py çš„æ–‡ä»¶åä¸º NumPy
python preprocess_data.py

# 5. å¢å¼ºå¤„ç†
cd preprocess_data
# é…ç½® enhanced_api_crawler.py çš„è¾“å…¥ä¸º preprocess_NumPy.csv
python enhanced_api_crawler.py
```
